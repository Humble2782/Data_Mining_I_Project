% Do not change document class, margins, fonts, etc.
\documentclass[a4paper,oneside,bibliography=totoc]{scrbook}

% some useful packages (add more as needed)
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{algorithm} % you can modify the algorithm style to your liking
\counterwithin{algorithm}{chapter} % so that algorithms have chapter numbers as well
\usepackage{algorithmic}
\usepackage{csquotes}
\usepackage{enumitem}
\renewcommand{\algorithmiccomment}[1]{\hfill\textit{// #1}}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks,citecolor=Green]{hyperref} % you may change/remove the colors
\usepackage{lipsum} % you do not need this
\usepackage{subcaption}

% \us prints an underscore (_) and allows a line break afterwards.
% \sls prints a slash (/) and allows a line break afterwards.
\newcommand{\us}{\_\allowbreak}
\newcommand{\sls}{/\allowbreak}

% chicago citation style
\usepackage{natbib}
\bibliographystyle{chicagoa}
\setcitestyle{authoryear,round,semicolon,aysep={},yysep={,}} \let\cite\citep

% example enviroments (add more as needed)
\newtheorem{definition}{Definition} \newtheorem{proposition}{Proposition}

\begin{document}


% Quick fix to remove the 0 in front of sections.
\makeatletter
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\arabic{section}.\arabic{subsection}}
\renewcommand\thesubsubsection{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}
\makeatother



\frontmatter \subject{Project Report} % change to appropriate type
\title{Predicting Injury Severity in Road Accidents: A Real-Time Classification Approach}
\author{
  David Cebulla (1922129)\\
  Gabriel Himmelein (1649181)\\
  Lukas Ott (1842341)\\
  Artur Loreit (2268917)\\
  Aaron Niemesch (1836924)
} \date{November 23, 2025}
\publishers{{\small Submitted to}\\
  Data and Web Science Group\\
  Dr.\ Sven Hertling\\
  University of Mannheim\\}
\maketitle

% none of the things below is needed, but you may add them if you feel that they
% are helpful for your work \listofalgorithms \listoffigures \listoftables
% \listtheorems{definition} \listtheorems{proposition}


% okay, start new numbering ... here is where it really starts
\mainmatter

\section{Application Area and Goals (0.5 pages)}

Modern intelligent and connected vehicle systems, such as the mandatory European eCall service, are designed to automatically transmit crucial accident data to emergency centers when a crash occurs. These transmissions typically include location, timestamp, and the number of passengers but lack information on the severity of injuries: a critical shortcoming for emergency services, as this information is vital for prioritizing rescue efforts and optimizing medical response times.

To address this gap, we focus on leveraging historical accident data provided by the French National Interministerial Observatory for Road Safety (ONISR). This organization maintains the official “Bulletins d’Analyse des Accidents Corporels de la Circulation” (BAAC), a national database that records all injury accidents on public roads in France. The dataset captures detailed multi-table information covering the circumstances of each accident (Caractéristiques), the location and infrastructure (Lieux), the vehicles involved (Véhicules), and the individual users (Usagers). These data entries include rich contextual variables such as road category, lighting and weather conditions, vehicle type, and the user’s role and behavior at the time of the accident.

Each accident record specifies the injury outcome (grav) for every participant, coded as uninjured, lightly injured, hospitalized, or killed. Although the ONISR database provides this information retrospectively (sometimes up to 30 days after the event) it represents a uniquely valuable source for supervised learning aimed at approximating these outcomes in real time.

The goal of this project is to develop a machine learning classifier capable of predicting injury severity immediately after an accident, based solely on the information that would realistically be available to emergency responders or vehicle telematics systems at the moment of impact. Such a model can significantly enhance first-responder coordination by providing an automated injury risk assessment, enabling faster triage and more efficient resource allocation.

\section{Structure and Size of the Data Set}

Our analysis uses the "Annual Road Traffic Injury Databases" from 2019--2023, provided by ONISR. The data is supplied in four files per year (characteristics, locations, users, and vehicles) and includes features such as road conditions, weather, and user information. Recognizing the one-to-many relationship where each accident involves multiple participants, we defined our unit of analysis at the \textbf{individual level}. The \texttt{users} table serves as the base for our dataset.

Directly after merging the accident characteristics, locations, users, and vehicle tables, and prior to any further preprocessing steps, the consolidated dataset comprised a total of 619,817 records and 71 columns. Processing the yearly data reveals an annual volume ranging between approximately 105,000 and 133,000 records per year. The final consolidated dataset was then partitioned into a training and validation set of \textbf{493,214 samples} (covering 2019--2022) and a test set of \textbf{125,505 samples} (covering 2023).

The features we have selected are listed below. They are categorized into Original Features (retained from raw data) and Engineered Features (calculated to model complex relationships). The final dataset consists of \textbf{57 features}, comprising \textbf{23 original columns} retained from the raw data and \textbf{34 engineered features} calculated to model complex relationships.

\begin{description}
  [leftmargin=0pt]
\item[Time context] \hfill \\
{\raggedright \small\texttt{\{time\us of\us day, hour\us sin\sls cos, day\us of\us week\us sin\sls cos, month\us sin\sls cos, day\us of\us year\us sin\sls cos\}} \par}
Captures seasonality and daily patterns using cyclical sine/cosine transformations for time units. Also includes \texttt{time\us of\us day}, which groups hours into broader categories (e.g., Night, Rush Hour).

\item[Geospatial location] \hfill \\
{\raggedright \small\texttt{\{latitude, longitude\}} \par}
GPS coordinates (WGS84) utilized for spatial analysis and mapping.

\item[Environment \& Roadway] \hfill \\
{\raggedright \small\texttt{\{lighting\us ordinal, weather\us ordinal, location, infrastructure, accident\us situation, horizontal\us alignment, reserved\us lane\us present, speed\us limit, road\us complexity\us index, surface\us quality\us indicator\}} \par}
Combines physical site attributes (urban/rural status, alignment, infrastructure type) with risk-based ordinals for lighting and weather. Engineered indices quantify road complexity (0--10 scale) and surface quality.

\item[Crash dynamics \& Maneuvers] \hfill \\
{\raggedright \small\texttt{\{type\us of\us collision, initial\us point\us of\us impact, fixed\us obstacle\us struck, mobile\us obstacle\us struck, main\us maneuver\us before\us accident, impact\us score, impact\us delta\}} \par}
Describes the collision mechanics, including maneuvers, impact points, and obstacles. Derived metrics like \texttt{impact\us score} and \texttt{impact\us delta} quantify the relative risk based on vehicle size differences.

\item[Vehicle attributes \& Involvement] \hfill \\
{\raggedright \small\texttt{\{motor\us type, vehicle\us category\us simplified, vehicle\us category\us involved\us [type]\}} \par}
Specifies the primary vehicle's type and motorization. Includes binary flags indicating if specific other vehicle types (e.g., heavy trucks, bicycles, buses) were involved in the accident.

\item[Personal attributes] \hfill \\
{\raggedright \small\texttt{\{role, sex, age, age\us group, position, pedestrian\us location, pedestrian\us action\}} \par}
Covers demographic data (age, sex), the user's role (driver, passenger, pedestrian), seating position, and specific actions or locations for pedestrians at the time of the accident.

\item[Safety equipment usage] \hfill \\
{\raggedright \small\texttt{\{used\us belt, used\us helmet, used\us child\us restraint, used\us airbag\}} \par}
Binary variables indicating the use of protective gear (seatbelts, helmets) or the deployment of airbags.

\item[Accident Persona Clustering] \hfill \\
{\raggedright \small\texttt{\{cluster\}} \par}
A categorical feature derived from unsupervised K-Prototypes clustering. It groups accidents into distinct "personas" (e.g., 0, 1, 2) based on a combination of numerical and categorical attributes to capture complex, non-linear patterns in the data.

\item[Target / Outcome] \hfill \\
{\raggedright \small\texttt{\{injury\us target\}} \par}
The engineered ordinal target variable classifying injury severity into three levels: 0 (Uninjured), 1 (Lightly Injured), and 2 (Hospitalized or Dead).
\end{description}

\section{Preprocessing}

Given the nature of the "Annual Road Traffic Injury Database" as a raw database output provided by ONISR in multiple separate tables with complex many-to-one relationships, extensive preprocessing was required. The pipeline is designed to transform the disjointed raw data into a singular, model-ready tabular representation.

\subsection{Data Standardization and Key Generation}
The initial step involved normalizing column names to English equivalents. A critical challenge was the inconsistency in user identification across years. Data from 2022 onwards included a distinct \texttt{id\us user}, whereas data from 2019 and 2020 did not. To ensure a consistent unit of analysis across all years, we implemented a synthetic key generation strategy. For older data, we generated a unique identifier by combining the accident ID with a cumulative count of users within that accident (e.g., \texttt{2019000001\us U1}). This ensured that every individual involved in an accident could be uniquely tracked and merged with their respective vehicle and accident characteristics.

\subsection{Advanced Data Merging strategies}
A user-centric view was adopted for merging, treating each participant as an independent instance. While accident characteristics (weather, time) could be joined directly, the relationship between users, their vehicles, and opposing vehicles required complex logic.

\subsubsection{Vehicle Antagonist Resolution}
A significant predictor of injury severity is the disparity between the user's vehicle and the "opposing" entity (the antagonist). Since a simple join cannot determine which of the multiple vehicles in an accident caused the injury, we engineered a selection algorithm. We assigned an \texttt{impact\us score} to vehicle categories based on mass and risk (e.g., HGV Truck = 6, Bicycle = 2).
For multi-vehicle accidents, the pipeline identifies the "antagonist" vehicle as the one involved in the same accident with the highest impact score, excluding the user's own vehicle. For pedestrians, the striking vehicle is explicitly identified. This allows us to calculate an \texttt{impact\us delta}, representing the structural disadvantage of the user (e.g., a cyclist hit by a truck results in a high negative delta).

\subsubsection{Location Deduplication}
Contrary to the dataset description, multiple location entries were found for single accident IDs, likely due to first responders logging entries for every intersecting street. To resolve this, we implemented a \texttt{completeness\us score}. We assigned weights to critical columns (Road Category: 2.0, Speed Limit: 2.0, others: 1.0). For each accident, the location entry with the highest weighted score, indicating the most data-rich description of the scene, was selected, ensuring the model trains on the highest quality data available.

\subsection{Handling Missing Values (Imputation Strategy)}
We distinguished between "structural missingness" (values that should not exist) and "data quality missingness" (values that are unknown).

\begin{itemize}
    \item \textbf{Structural Missingness:} Pedestrians, by definition, do not have a vehicle category or motor type. For these cases, we explicitly imputed a value of \texttt{-1} or \texttt{'none'} to indicate "Not Applicable," preventing the model from treating these as missing data.
    \item \textbf{Data Quality Missingness:} For users who \textit{should} have data (e.g., drivers) but lack it, we imputed a value of \texttt{0} or \texttt{'Unknown'}.
    \item \textbf{Other Vehicle Imputation:} If no opposing vehicle was involved, columns related to the "other" vehicle were set to \texttt{-1}. However, if a second vehicle ID existed but its characteristics were missing, we imputed \texttt{Unknown} to differentiate this state from single-vehicle accidents.
\end{itemize}
Finally, rows missing the target variable \texttt{injury\us severity} were dropped, as they cannot be used for supervised learning.

\subsection{Feature Engineering}
To capture complex non-linear relationships, we generated 34 new features across four domains.

\subsubsection{Temporal Cyclical Features}
Raw timestamps are ill-suited for many models due to the discontinuity between 23:59 and 00:00. We decomposed time into cyclical components using Sine and Cosine transformations for hours, days of the week, and months. Additionally, we bucketed hours into a \texttt{time\us of\us day} feature (Night, Morning Rush, Midday, Evening Rush) to assist tree-based models in identifying high-level patterns.

\subsubsection{Road Complexity Index}
We hypothesized that complex road environments increase accident probability but might decrease severity due to lower speeds. We engineered a \texttt{road\us complexity\us index}, a composite score normalized between 0 and 10. This index aggregates weighted scores from:
\begin{itemize}
    \item \textbf{Intersection Type:} High weights for roundabouts and multi-branch intersections.
    \item \textbf{Road Category:} Higher weights for urban communal ways vs. motorways.
    \item \textbf{Traffic Regime:} Penalties for variable assignment lanes.
    \item \textbf{Lane Count:} Higher complexity for multi-lane roads.
\end{itemize}
Complementing this, a binary \texttt{surface\us quality\us indicator} was created, set to 1 only if both the pavement condition was normal and the longitudinal profile was flat.

\subsubsection{Vehicle and User Attributes}
Vehicle categories were simplified from over 30 specific codes into 6 broad classes (Bicycle, Powered 2-3 Wheeler, Light Motor Vehicle, HGV/Truck, Bus/Coach, Other) to reduce dimensionality.
For users, we transformed the \texttt{year\us of\us birth} into an \texttt{age} feature and further binned it into sociologically relevant \texttt{age\us groups} (e.g., Child/Teen, Senior). Safety equipment flags (seatbelts, helmets, airbags) were consolidated from three separate columns into binary "Used/Not Used" indicators to resolve data sparsity.

\subsection{Feature Selection \& Cleaning}
Following engineering, the dataset underwent a rigorous cleaning process. Invalid data, such as speed limits exceeding 130 km/h or negative values for age, were filtered out. We removed high-cardinality identifiers (IDs, address strings) and columns with excessive missingness (e.g., \texttt{width\us central\us reservation}) that offered little predictive value.
Crucially, the raw target variable \texttt{injury\us severity} (4 classes) was re-mapped to an ordinal \texttt{injury\us target} (0: Uninjured, 1: Light Injury, 2: Hospitalized/Dead) to address class imbalance and better reflect the triage needs of first responders. The final dataset consists of 57 refined features ready for the modeling pipeline.

\subsection{Resampling}
Regarding the target value of injury severity, the dataset exhibits a clear class imbalance towards less severe cases (47\% non-injured, 36\% injured, and 16\% heavily injured) biasing models trained towards the majority class. Given the importance of correctly assessing cases of heavy injury, resampling was applied to the dataset to remove class imbalance.
Both over- (SMOTE) and undersampling were considered and tested. Given the large amount of data at disposal (over 400k) and considering compute constraints, random undersampling (130k) was ultimately chosen.

\section{Data Mining}
\label{sec:dm}
We partition the dataset into a training set (2019–2022) and a test set (2023). Our primary evaluation metric is the macro F1-score, chosen to prioritize recall for the critical "severely injured" class without introducing the sensitivity of arbitrary cost matrices. Instead of using a simple majority-vote baseline, we implemented a domain-specific baseline that relies exclusively on the speed-limit feature to predict accident severity:
\[
\hat{y} =
\begin{cases}
\text{uninjured}, & \text{if } \text{speed\_limit} \le 50, \\[4pt]
\text{injured}, & \text{if } \text{speed\_limit} < 100, \\[4pt]
\text{severely injured}, & \text{otherwise}.
\end{cases}
\]
Given the ordinal nature of the target variable, we also considered weighted Cohen’s kappa. However, considering the high cost of missing a severe injury in an emergency response context, optimizing macro-F1 ensures that the minority class (severe injuries) is not overwhelmed by the majority class (uninjured).


\subsection{Classification: Model Selection}
To gain an initial understanding of the difficulty of the prediction task, we experimented with a broad range of machine learning models while applying only minimal hyperparameter tuning including models based on logistic regression (ordinal, lasso, ridge), ensembles (Random Forests, HistGradientBoosting, CatBoost) and simple neural networks.
%
Across these experiments, we observed that all machine learning models substantially outperformed the baseline method. While originally considered, methods explicitly designed to leverage the ordinal structure of the target variable did not achieve better performance compared to other approaches in terms of both F1 and misclassifications error types, eliminating them from consideration. Applying Occam's Razor, our focus was narrowed to three models for fine-tuning and selection: Ridge Classification, Balanced Random Forest and CatBoost. 
%
While the first is Logistic Regression with applied L2-regularization and the second a random forest with rebalancing during subsampling, CatBoost is a boosting algorithm similar to XGBoost chosen for its improved support for categorical data, fitting to our data composition. 

\begin{table}[tb]
  \centering
  \begin{tabularx}{\textwidth}{l l X c}
    \toprule
    \textbf{Model} & \textbf{Hyperparameter} & \textbf{Search Space} & \textbf{Optimal Value} \\
    \midrule
    \textbf{Ridge} & alpha & $\{0.05, 0.10, \dots, 10\}$ & 2.0 \\
    \midrule
    \textbf{BRF} & n\_estimators & $[50,\,400] \cap \mathbb{Z}$ & 400 \\
    & max\_depth & $\{3, \dots, 20\}$ & 18 \\
    & min\_samples\_leaf & $\{1, \dots, 20\}$ & 1 \\
    & replacement & \{\texttt{True}, \texttt{False}\} & \texttt{False} \\
    & sampling\_strategy & \{\texttt{all}, \texttt{not minority}\} & \texttt{all} \\ 
    \midrule
    \textbf{CatBoost} & iterations & $\{1000, \dots, 7000\}$ & 5000 \\
    & learning\_rate & $[0.01,\,0.2]$ & 0.0194 \\
    & depth & $\{4, \dots, 10\}$ & 10 \\
    & l2\_leaf\_reg & $[10^{-2},\,10]$ & 0.01 \\
    & border\_count & $\{32, \dots, 255\}$ & 32 \\
    \bottomrule
  \end{tabularx}
  \caption{Search space and optimal hyperparameters for Ridge, BRF and CatBoost.}
  \label{tab:hyperparams}
\end{table}

Considering the size of our dataset and computational constraints, model selection in terms of hyperparameter tuning was conducted for each model using 3-fold cross validation with shuffling to avoid biases from the original ordering, utilizing Bayesian Optimization and F1-Macro for the ensembles. While Ridge Regression could only be tuned regarding its regularization strength $\alpha$, both ensemble methods offered more options regarding tree pruning relevant for avoiding overfitting. \autoref{tab:hyperparams} shows the hyperparameters considered.
%
Approaches selection was similarly achieved using both F1-Macro and confusion matrices, used to evaluate recall/misclassifications on (high) injury cases, with the same 3-fold cross validation.

% \begin{itemize}
%     \item \textbf{Ridge Classifier with Under-sampling:} 
%     This linear model was selected for its computational efficiency and interpretability. Ridge regularization ($L2$) effectively handles the potential multicollinearity arising from our engineered features (e.g., cyclical time features). We combined this with under-sampling of the majority class to counteract the linear model's sensitivity to class imbalance.
    
%     \item \textbf{Balanced Random Forest (BRF):} 
%     Standard Random Forests often bias towards the majority class. The Balanced Random Forest addresses this by under-sampling the majority class in the bootstrap sample for each tree. This method was chosen to improve recall for the "severely injured" class while maintaining the robustness of an ensemble method.
    
%     \item \textbf{CatBoost:} 
%     Gradient boosting often yields state-of-the-art results on tabular data. CatBoost was specifically selected for its native handling of categorical features, which constitute a large portion of our dataset. We utilized the \texttt{auto\_class\_weights\\='Balanced'} parameter to handle imbalance without external sampling strategies.
% \end{itemize}

\subsection{Clustering Strategy}
To identify distinct "Accident Personas," we explored four clustering algorithms, each chosen for a specific capability:

\begin{itemize}
    \item \textbf{K-Prototypes:} A hybrid extension of K-Means that handles mixed data types (numerical and categorical) natively. This is critical for our dataset, where features like 'road category' or 'vehicle type' carry significant semantic weight that cannot be captured by Euclidean distance alone.
    \item \textbf{HDBSCAN:} A density-based algorithm chosen for its ability to detect noise and clusters of varying shapes. Unlike partition-based methods, it does not force every point into a cluster, which is useful for identifying "outlier" accident types.
    \item \textbf{Agglomerative Clustering:} Used with Gower distance to explore hierarchical structures in the mixed dataset, offering a visual way to assess natural groupings via dendrograms.
\end{itemize}

\textbf{Cluster Profiling Methodology:}
To derive meaningful profiles from the clustered dataset, we conducted a structured categorical overrepresentation analysis. For each cluster and each categorical feature, we computed the conditional distribution $P(X = x \mid C = c)$ and compared it to the global distribution $P(X=x)$. A category was considered \emph{cluster-characteristic} if it satisfied the following criteria:
\begin{itemize}
    \item \textbf{Lift filter:} A minimum overrepresentation of $\text{lift}(x,c) = \frac{P(X=x \mid C=c)}{P(X=x)} > 1.5$.
    \item \textbf{Support filter:} The category must represent more than 3\% of observations within the cluster.
    \item \textbf{Dominance filter:} Features were excluded if the same dominant category appeared in all clusters (e.g., "Daylight").
\end{itemize}

\section{Evaluation}

\subsection{Hyperparameter Tuning}
We optimized hyperparameters using macro-F1 as the objective function. For the \textbf{Ridge classifier}, a grid search yielded an optimal regularization parameter $\alpha=2.0$.
For the ensemble models, we employed Bayesian Optimization (30 iterations) with stratified 3-fold cross-validation.

The tuning process for the \textbf{Balanced Random Forest} revealed that a high model complexity was necessary to capture the nuances of severe accidents. The optimal configuration required a large number of estimators ($n=400$) and a significant maximum depth ($depth=18$). Furthermore, we found that disabling replacement in the bootstrap sampling improved diversity among the trees.

In contrast, the optimization for \textbf{CatBoost} converged towards parameters that mitigated overfitting. The optimal learning rate was relatively low ($0.0194$), and the depth was moderate ($10$). The regularization parameter ($l2\_leaf\_reg=0.01$) suggested that the model relied heavily on the natural structure of the categorical splits rather than aggressive weight penalties.

\subsection{Classifier Evaluation}
We evaluated the models on the held-out test set (2023). This dataset preserves the natural distribution of the problem (47\% non-injured, 36\% injured, 16\% heavily injured). We report class-wise precision, recall, and F1-scores. This granular evaluation is critical because a high global accuracy could hide a model's failure to detect severe injuries: the most costly error in our domain.


\subsection{Clustering Evaluation}
Clustering performance was assessed via Silhouette scores (Table~\ref{tab:cluster_results}). While HDBSCAN and Agglomerative Clustering yielded higher raw scores ($>0.08$), deeper inspection revealed they produced degenerate solutions where over 85\% (HDBSCAN) or 100\% (Agglomerative) of the data collapsed into a single giant cluster. Such partitions offer no analytical value for differentiating accident types. 
In contrast, K-Prototypes with $k=5$ produced a more balanced distribution (largest cluster $\approx 39\%$) with clear semantic distinctions, offering the best trade-off between mathematical cohesion and practical interpretability.

\begin{table}[h!]
\centering
\small
\begin{tabular}{l c c c}
\hline
\textbf{Algorithm} & \textbf{Param} & \textbf{Silhouette} & \textbf{Largest Cluster [\%]} \\
\hline
K-Prototypes   & 5  & 0.041 & 38.8 \\
Agglomerative  & 3  & 0.107 & 100.0 \\
HDBSCAN        & 10 & 0.089 & 85.4 \\
\hline
\end{tabular}
\caption{Comparison of clustering algorithms (abbreviated).}
\label{tab:cluster_results}
\end{table}

\section{Results}

\subsection{Classification Results}
This section presents the performance of the three trained classification models.
A summary of the core evaluation metrics is provided in table \ref{tab:model_comparison}.
\begin{table}[t]
\centering
\small
\setlength{\tabcolsep}{6pt}
\begin{tabular}{lcccccccccccc}
\toprule
\textbf{} 
    & \multicolumn{3}{c}{\textbf{RC}} 
    & \multicolumn{3}{c}{\textbf{BRF}} 
    & \multicolumn{3}{c}{\textbf{CB}}
    & \multicolumn{3}{c}{\textbf{BL}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
& P & R & F1
& P & R & F1
& P & R & F1
& P & R & F1 \\
\midrule

\textbf{Uninjured}
& 0.83 & 0.74 & 0.78 
& 0.87 & 0.73 & 0.80
& 0.85 & 0.77 & 0.81
& 0.50 & 0.64 & 0.56 \\

\textbf{Injured}
& 0.62 & 0.50 & 0.55
& 0.63 & 0.61 & 0.62
& 0.64 & 0.63 & 0.64
& 0.34 & 0.30 & 0.32 \\

\textbf{Severe} 
& 0.42 & 0.74 & 0.54
& 0.47 & 0.72 & 0.56
& 0.51 & 0.65 & 0.57
& 0.16 & 0.08 & 0.10 \\
\midrule

\textbf{Macro F1}
& \multicolumn{3}{c}{0.62} 
& \multicolumn{3}{c}{0.66} 
& \multicolumn{3}{c}{0.67} 
& \multicolumn{3}{c}{0.33} \\

\textbf{Micro F1}
& \multicolumn{3}{c}{0.66} 
& \multicolumn{3}{c}{0.69} 
& \multicolumn{3}{c}{0.71} 
& \multicolumn{3}{c}{0.40} \\

\textbf{Cohen's Kappa}
& \multicolumn{3}{c}{0.6021} 
& \multicolumn{3}{c}{0.6343} 
& \multicolumn{3}{c}{0.6488} 
& \multicolumn{3}{c}{0.0910} \\

\textbf{Macro AUC}
& \multicolumn{3}{c}{-}
& \multicolumn{3}{c}{0.72296}
& \multicolumn{3}{c}{0.72929}
& \multicolumn{3}{c}{-} \\

\textbf{Micro AUC}
& \multicolumn{3}{c}{-}
& \multicolumn{3}{c}{0.78559}
& \multicolumn{3}{c}{0.80404}
& \multicolumn{3}{c}{-} \\
\bottomrule
\end{tabular}

\caption{\small Comparison of a Ridge Classifier (RC), Balanced Random Forest (BRF), CatBoost (CB), and a rule-based speed-limit baseline (BL). For each model, we report per-class precision (P), recall (R), and F1-score, as well as macro F1, weighted F1, and quadratically weighted Cohen's kappa (Kappa). Class supports in the test set are: Uninjured = 51{,}051, Injured = 39{,}476, and Severely Injured = 17{,}440.}
\label{tab:model_comparison}
\end{table}

\subsubsection{Per-Class Performance}
The \textbf{Uninjured} class is consistently the easiest to predict, with all machine learning models achieving recalls above 0.7. CatBoost performs best in this class (F1 = 0.81), benefiting from its ability to model nonlinear interactions between features. The BRF and RC models perform similarly (F1 = 0.80 and 0.78, respectively). The baseline severely underperforms, achieving only 0.56 F1. \\
For the \textbf{Injured} class, all models exhibit weaker recall (0.50–0.63), suggesting substantial overlap with both the Uninjured and Severely Injured classes. CatBoost again achieves the strongest performance, with balanced precision and recall (0.64 and 0.63), whereas the RC struggles with low recall (0.50), indicating that many Injured cases are misclassified as Uninjured or Severe. \\
The \textbf{Severely Injured} class displays the most interesting behavior: RC, BRF, and CB all achieve relatively high recall (0.65–0.74), but with lower precision (0.42–0.51). This reflects a consistent pattern across all models: they prefer to overpredict severe cases rather than risk missing them. Here, CatBoost achieves the highest F1-score (0.57).\\ \\
To better understand these classification patterns, Figure~\ref{fig:three_images} shows the row-normalized confusion matrices for all three models, where each cell represents the proportion of true class instances assigned to each predicted label. \\
Overall, similar trends appear across models. \textbf{Uninjured} cases are mainly confused with \textbf{Injured} (17–20\% for RC and BRF, 18\% for CatBoost), while confusion with the Severe class remains low (5–8\%). The \textbf{Injured} class shows the highest ambiguity, with substantial confusion toward Severe (34\% for RC, 27\% for BRF, 21\% for CatBoost) and some toward Uninjured (12–17\%). \textbf{Severely Injured} instances are generally identified reliably (65–74\%), with most misclassifications shifting toward Injured (19–29\%), and very few toward Uninjured (4–7\%), which is desirable from a safety standpoint.


\subsubsection{Aggregate Metrics}
Macro and micro F1-scores provide an overall assessment of model performance across classes. CatBoost 
achieves the highest macro F1 (0.67) and micro F1 (0.71), indicating strong performance both in balancing 
minority and majority classes and in overall classification accuracy. BRF follows closely with a macro F1 
of 0.66 and a micro F1 of 0.69, while RC performs slightly worse (macro F1 = 0.62, micro F1 = 0.66). 
The baseline is substantially weaker, achieving only 0.33 macro F1 and 0.40 micro F1.

Cohen's $\kappa$ further confirms these trends. CatBoost attains the highest agreement beyond chance 
($\kappa = 0.6488$), followed by BRF ($\kappa = 0.6343$) and RC ($\kappa = 0.6021$). The baseline performs 
close to chance level ($\kappa = 0.0910$), reinforcing its inadequacy as a predictive model.

\subsubsection{Precision--Recall AUC}
Since precision--recall curves are particularly informative for imbalanced classification tasks, we also 
compute micro and macro AUC scores. AUC values could not be computed for the Ridge Classifier and baseline 
because they do not output calibrated probabilistic predictions. Among the probabilistic models, CatBoost 
achieves the highest micro AUC (0.80404) and macro AUC (0.72929), slightly outperforming the Balanced 
Random Forest (micro AUC = 0.78559, macro AUC = 0.72296). These results indicate that CatBoost produces 
more separable precision--recall curves and leads to better threshold-independent discrimination across 
injury severity classes.

\subsubsection{Feature Importance}
\begin{table}[t]
\centering
\small
\setlength{\tabcolsep}{10pt}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Feature 1} & \textbf{Feature 2} & \textbf{Feature 3} \\
\midrule
RC
    & num\_powered\_2\_3\_wheeler 
    & num\_light\_motor\_vehicle
    & mobile\_obstacle\_struck \\
BRF
    & mobile\_obstacle 
    & impact\_delta 
    & fixed\_obstacle \\
CB
    & age\_group 
    & point\_of\_impact 
    & day\_of\_week \\
\bottomrule
\end{tabular}
\caption{\small Top three most important features identified by each classifier. Ridge importance is derived from coefficient magnitudes, BRF importance from mean decrease in impurity, and CatBoost importance from built-in feature attribution.}
\label{tab:feature_importance}
\end{table}
To interpret the models' decision-making behavior, Table~\ref{tab:feature_importance} summarizes the three most influential features per classifier. Feature importance was computed using model-specific methods: coefficient magnitudes for the Ridge Classifier, mean decrease in impurity for the Balanced Random Forest, and CatBoost’s internal attribution scores.

Overall, the Ridge Classifier primarily relies on variables describing the number and types of vehicles involved, reflecting its focus on structural crash characteristics. The Balanced Random Forest emphasizes features related to the collision type and crash intensity, which aligns with its ability to capture nonlinear tree-based interactions. CatBoost, in contrast, highlights a more diverse mix of demographic, situational, and crash-mechanics features, indicating that it leverages broader and more heterogeneous information. This richer feature utilization likely contributes to its superior predictive performance.



\subsubsection{Summary}
Overall, CatBoost consistently yields the best results across nearly all metrics, particularly for the 
challenging \emph{Injured} and \emph{Severely Injured} classes. The Balanced Random Forest performs 
comparably well and represents a strong traditional machine learning baseline. The Ridge Classifier is 
competitive despite its simplicity but shows clear limitations relative to tree-based models. The rule-based 
speed-limit baseline performs poorly, underscoring that injury severity prediction requires substantially 
richer information than road speed limits alone.

These results highlight the benefits of flexible, non-linear models—especially CatBoost—in capturing the 
complex interactions underlying road traffic injury severity.

The CatBoost confusion matrix shows that about 95\% of severely injured cases are at least classified as injured, so a real-time system could flag most severe accidents early and support faster emergency response. However, this comes at the cost of inefficient resource allocation, because also around 5\% of non-injury cases would be predicted as severely injured and trigger unnecessary deployments, illustrating a fundamental trade-off between saving lives and resource efficiency. Moreover, the remaining 5\% of severely injured cases that are predicted as uninjured are a critical limitation: such a system cannot replace emergency calls or human judgement but should instead be viewed as a decision-support tool that helps responders prioritise and detect severe accidents that might otherwise be recognised too late.

\begin{figure}[tb]
    \centering
    \includegraphics[width=\textwidth]{images/confusion_matrices_comparison.pdf}
    \caption{Generalization Performance: Confusion Matrices}
    \label{fig:confusion_matrices}
\end{figure}

\subsection{Identified Accident Personas}
The clustering analysis successfully identified five distinct "accident personas," summarizing complex categorical patterns. These profiles were derived by analyzing features that showed a statistical lift $>1.5$ within each cluster.

\subsubsection*{Cluster 0: Midday pedestrian-involved accidents with older road users}
This cluster captures accidents occurring predominantly around midday in moderate traffic conditions. It is uniquely characterized by a disproportionate involvement of older road users and pedestrians. The accident locations often correlate with semi-urban environments where mixed traffic (pedestrians and vehicles) interacts during daylight hours.

\subsubsection*{Cluster 1: Night-time accidents with younger adults}
This profile describes accidents occurring during the night, marked by significantly reduced visibility and lighting conditions. The demographic analysis reveals a strong overrepresentation of younger adults (18–30 years). The lack of natural light appears to be a compounding risk factor, potentially amplifying the severity of incidents involving less experienced drivers.

\subsubsection*{Cluster 2: Morning rush hour collisions}
Collisions in this cluster are tightly synchronized with the morning peak hours (typically 07:00–09:00). They correlate strongly with high traffic density. The features suggest standard commuting accidents, likely involving rear-end collisions or minor impacts due to congestion, though the involvement of two-wheelers in rush hour traffic remains a severity risk.

\subsubsection*{Cluster 3: High-speed urban location collisions}
This cluster identifies high-frequency accidents occurring in urban settings, particularly at intersections. While the speeds are generally lower than rural accidents, the complexity of the road environment (intersections, crossings) is high. There is a distinct sub-pattern of pedestrian involvement, suggesting these are often vehicle-to-pedestrian conflicts at crossing points.

\subsubsection*{Cluster 4: Low-speed urban maneuver collisions}
Distinct from Cluster 3, these accidents are characterized by low-speed maneuvers in built-up areas, such as parking or turning in narrow streets. The specific "maneuver" features are highly predictive here. While the frequency of these accidents is high, the impact forces are typically lower, often resulting in vehicle damage rather than severe injury, though vulnerable users remain at risk.

\newpage
\section*{Ehrenwörtliche Erklärung}
Ich versichere, dass ich die beiliegende Bachelor-, Master-, Seminar-, oder
Projektarbeit ohne Hilfe Dritter und ohne Benutzung anderer als der angegebenen
Quellen und in der untenstehenden Tabelle angegebenen Hilfsmittel angefertigt
und die den benutzten Quellen wörtlich oder inhaltlich entnommenen Stellen als
solche kenntlich gemacht habe. Diese Arbeit hat in gleicher oder ähnlicher Form
noch keiner Prüfungsbehörde vorgelegen. Ich bin mir bewusst, dass eine falsche
Erklärung rechtliche Folgen haben wird.

% Declare below which AI tools you used in the process of writing your work,
% including text, image, code, and data generation. If you used a tool for a
% purpose not included in the list yet, add it to the list.
\begin{center}
  \textbf{Declaration of Used AI Tools} \\[.3em]
  \begin{tabularx}{\textwidth}{lXlc}
    \toprule
    Tool & Purpose & Where? & Useful? \\
    \midrule
    Gemini 2.5/3 Pro & Rephrasing & Throughout & +++ \\
    Gemini 2.5/3 Pro & Code Generation and Code Debugging & Throughout & +++ \\
    \bottomrule
  \end{tabularx}
\end{center}

\vspace{2cm}
\noindent Unterschrift\\
\noindent Mannheim, den 30.~Oktober 2025 \hfill
\end{document}