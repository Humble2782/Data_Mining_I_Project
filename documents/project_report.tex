% Do not change document class, margins, fonts, etc.
\documentclass[a4paper,oneside,bibliography=totoc]{scrbook}

% some useful packages (add more as needed)
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{algorithm} % you can modify the algorithm style to your liking
\counterwithin{algorithm}{chapter} % so that algorithms have chapter numbers as well
\usepackage{algorithmic}
\usepackage{csquotes}
\usepackage{enumitem}
\renewcommand{\algorithmiccomment}[1]{\hfill\textit{// #1}}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks,citecolor=Green]{hyperref} % you may change/remove the colors
\usepackage{lipsum} % you do not need this

% \us prints an underscore (_) and allows a line break afterwards.
% \sls prints a slash (/) and allows a line break afterwards.
\newcommand{\us}{\_\allowbreak}
\newcommand{\sls}{/\allowbreak}

% chicago citation style
\usepackage{natbib}
\bibliographystyle{chicagoa}
\setcitestyle{authoryear,round,semicolon,aysep={},yysep={,}} \let\cite\citep

% example enviroments (add more as needed)
\newtheorem{definition}{Definition} \newtheorem{proposition}{Proposition}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\begin{document}


% Quick fix to remove the 0 in front of sections.
\makeatletter
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\arabic{section}.\arabic{subsection}}
\renewcommand\thesubsubsection{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}
\makeatother



\frontmatter \subject{Project Report} % change to appropriate type
\title{Predicting Injury Severity in Road Accidents: A Real-Time Classification Approach}
\author{
  David Cebulla (1922129)\\
  Gabriel Himmelein (1649181)\\
  Lukas Ott (1842341)\\
  Artur Loreit (2268917)\\
  Aaron Niemesch (1836924)
} \date{November 23, 2025}
\publishers{{\small Submitted to}\\
  Data and Web Science Group\\
  Dr.\ Sven Hertling\\
  University of Mannheim\\}
\maketitle

% none of the things below is needed, but you may add them if you feel that they
% are helpful for your work \listofalgorithms \listoffigures \listoftables
% \listtheorems{definition} \listtheorems{proposition}


% okay, start new numbering ... here is where it really starts
\mainmatter

\section{Application Area and Goals (0.5 pages)}

Modern intelligent and connected vehicle systems, such as the mandatory European eCall service, are designed to automatically transmit crucial accident data to emergency centers when a crash occurs. These transmissions typically include location, timestamp, and the number of passengers but lack information on the severity of injuries: a critical shortcoming for emergency services, as this information is vital for prioritizing rescue efforts and optimizing medical response times.

To address this gap, we focus on leveraging historical accident data provided by the French National Interministerial Observatory for Road Safety (ONISR). This organization maintains the official “Bulletins d’Analyse des Accidents Corporels de la Circulation” (BAAC), a national database that records all injury accidents on public roads in France. The dataset captures detailed multi-table information covering the circumstances of each accident (Caractéristiques), the location and infrastructure (Lieux), the vehicles involved (Véhicules), and the individual users (Usagers). These data entries include rich contextual variables such as road category, lighting and weather conditions, vehicle type, and the user’s role and behavior at the time of the accident.

Each accident record specifies the injury outcome (grav) for every participant, coded as uninjured, lightly injured, hospitalized, or killed. Although the ONISR database provides this information retrospectively (sometimes up to 30 days after the event) it represents a uniquely valuable source for supervised learning aimed at approximating these outcomes in real time.

The goal of this project is to develop a machine learning classifier capable of predicting injury severity immediately after an accident, based solely on the information that would realistically be available to emergency responders or vehicle telematics systems at the moment of impact. Such a model can significantly enhance first-responder coordination by providing an automated injury risk assessment, enabling faster triage and more efficient resource allocation.

\section{Structure and Size of the Data Set}

Our analysis uses the "Annual Road Traffic Injury Databases" from 2019--2023, provided by ONISR. The data is supplied in four files per year (characteristics, locations, users, and vehicles) and includes features such as road conditions, weather, and user information. Recognizing the one-to-many relationship where each accident involves multiple participants, we defined our unit of analysis at the \textbf{individual level}. The \texttt{users} table serves as the base for our dataset.

Directly after merging the accident characteristics, locations, users, and vehicle tables, and prior to any further preprocessing steps, the consolidated dataset comprised a total of 619,817 records and 71 columns. Processing the yearly data reveals an annual volume ranging between approximately 105,000 and 133,000 records per year. The final consolidated dataset was then partitioned into a training and validation set of \textbf{493,214 samples} (covering 2019--2022) and a test set of \textbf{125,505 samples} (covering 2023).

The features we have selected are listed below. They are categorized into Original Features (retained from raw data) and Engineered Features (calculated to model complex relationships). The final dataset consists of \textbf{57 features}, comprising \textbf{23 original columns} retained from the raw data and \textbf{34 engineered features} calculated to model complex relationships.

\begin{description}
  [leftmargin=0pt]
\item[Time context] \hfill \\
{\raggedright \small\texttt{\{time\us of\us day, hour\us sin\sls cos, day\us of\us week\us sin\sls cos, month\us sin\sls cos, day\us of\us year\us sin\sls cos\}} \par}
Captures seasonality and daily patterns using cyclical sine/cosine transformations for time units. Also includes \texttt{time\us of\us day}, which groups hours into broader categories (e.g., Night, Rush Hour).

\item[Geospatial location] \hfill \\
{\raggedright \small\texttt{\{latitude, longitude\}} \par}
GPS coordinates (WGS84) utilized for spatial analysis and mapping.

\item[Environment \& Roadway] \hfill \\
{\raggedright \small\texttt{\{lighting\us ordinal, weather\us ordinal, location, infrastructure, accident\us situation, horizontal\us alignment, reserved\us lane\us present, speed\us limit, road\us complexity\us index, surface\us quality\us indicator\}} \par}
Combines physical site attributes (urban/rural status, alignment, infrastructure type) with risk-based ordinals for lighting and weather. Engineered indices quantify road complexity (0--10 scale) and surface quality.

\item[Crash dynamics \& Maneuvers] \hfill \\
{\raggedright \small\texttt{\{type\us of\us collision, initial\us point\us of\us impact, fixed\us obstacle\us struck, mobile\us obstacle\us struck, main\us maneuver\us before\us accident, impact\us score, impact\us delta\}} \par}
Describes the collision mechanics, including maneuvers, impact points, and obstacles. Derived metrics like \texttt{impact\us score} and \texttt{impact\us delta} quantify the relative risk based on vehicle size differences.

\item[Vehicle attributes \& Involvement] \hfill \\
{\raggedright \small\texttt{\{motor\us type, vehicle\us category\us simplified, vehicle\us category\us involved\us [type]\}} \par}
Specifies the primary vehicle's type and motorization. Includes binary flags indicating if specific other vehicle types (e.g., heavy trucks, bicycles, buses) were involved in the accident.

\item[Personal attributes] \hfill \\
{\raggedright \small\texttt{\{role, sex, age, age\us group, position, pedestrian\us location, pedestrian\us action\}} \par}
Covers demographic data (age, sex), the user's role (driver, passenger, pedestrian), seating position, and specific actions or locations for pedestrians at the time of the accident.

\item[Safety equipment usage] \hfill \\
{\raggedright \small\texttt{\{used\us belt, used\us helmet, used\us child\us restraint, used\us airbag\}} \par}
Binary variables indicating the use of protective gear (seatbelts, helmets) or the deployment of airbags.

\item[Accident Persona Clustering] \hfill \\
{\raggedright \small\texttt{\{cluster\}} \par}
A categorical feature derived from unsupervised K-Prototypes clustering. It groups accidents into distinct "personas" (e.g., 0, 1, 2) based on a combination of numerical and categorical attributes to capture complex, non-linear patterns in the data.

\item[Target / Outcome] \hfill \\
{\raggedright \small\texttt{\{injury\us target\}} \par}
The engineered ordinal target variable classifying injury severity into three levels: 0 (Uninjured), 1 (Lightly Injured), and 2 (Hospitalized or Dead).
\end{description}

\section{Preprocessing}

Given the nature of the "Annual Road Traffic Injury Database" as a raw database output provided by ONISR in multiple separate tables with complex many-to-one relationships, extensive preprocessing was required. The pipeline is designed to transform the disjointed raw data into a singular, model-ready tabular representation.

\subsection{Data Standardization and Key Generation}
The initial step involved normalizing column names to English equivalents. A critical challenge was the inconsistency in user identification across years. Data from 2022 onwards included a distinct \texttt{id\us user}, whereas data from 2019 and 2020 did not. To ensure a consistent unit of analysis across all years, we implemented a synthetic key generation strategy. For older data, we generated a unique identifier by combining the accident ID with a cumulative count of users within that accident (e.g., \texttt{2019000001\us U1}). This ensured that every individual involved in an accident could be uniquely tracked and merged with their respective vehicle and accident characteristics.

\subsection{Advanced Data Merging strategies}
A user-centric view was adopted for merging, treating each participant as an independent instance. While accident characteristics (weather, time) could be joined directly, the relationship between users, their vehicles, and opposing vehicles required complex logic.

\subsubsection{Vehicle Antagonist Resolution}
A significant predictor of injury severity is the disparity between the user's vehicle and the "opposing" entity (the antagonist). Since a simple join cannot determine which of the multiple vehicles in an accident caused the injury, we engineered a selection algorithm. We assigned an \texttt{impact\us score} to vehicle categories based on mass and risk (e.g., HGV Truck = 6, Bicycle = 2).
For multi-vehicle accidents, the pipeline identifies the "antagonist" vehicle as the one involved in the same accident with the highest impact score, excluding the user's own vehicle. For pedestrians, the striking vehicle is explicitly identified. This allows us to calculate an \texttt{impact\us delta}, representing the structural disadvantage of the user (e.g., a cyclist hit by a truck results in a high negative delta).

\subsubsection{Location Deduplication}
Contrary to the dataset description, multiple location entries were found for single accident IDs, likely due to first responders logging entries for every intersecting street. To resolve this, we implemented a \texttt{completeness\us score}. We assigned weights to critical columns (Road Category: 2.0, Speed Limit: 2.0, others: 1.0). For each accident, the location entry with the highest weighted score, indicating the most data-rich description of the scene, was selected, ensuring the model trains on the highest quality data available.

\subsection{Handling Missing Values (Imputation Strategy)}
We distinguished between "structural missingness" (values that should not exist) and "data quality missingness" (values that are unknown).

\begin{itemize}
    \item \textbf{Structural Missingness:} Pedestrians, by definition, do not have a vehicle category or motor type. For these cases, we explicitly imputed a value of \texttt{-1} or \texttt{'none'} to indicate "Not Applicable," preventing the model from treating these as missing data.
    \item \textbf{Data Quality Missingness:} For users who \textit{should} have data (e.g., drivers) but lack it, we imputed a value of \texttt{0} or \texttt{'Unknown'}.
    \item \textbf{Other Vehicle Imputation:} If no opposing vehicle was involved, columns related to the "other" vehicle were set to \texttt{-1}. However, if a second vehicle ID existed but its characteristics were missing, we imputed \texttt{Unknown} to differentiate this state from single-vehicle accidents.
\end{itemize}
Finally, rows missing the target variable \texttt{injury\us severity} were dropped, as they cannot be used for supervised learning.

\subsection{Feature Engineering}
To capture complex non-linear relationships, we generated 34 new features across four domains.

\subsubsection{Temporal Cyclical Features}
Raw timestamps are ill-suited for many models due to the discontinuity between 23:59 and 00:00. We decomposed time into cyclical components using Sine and Cosine transformations for hours, days of the week, and months. Additionally, we bucketed hours into a \texttt{time\us of\us day} feature (Night, Morning Rush, Midday, Evening Rush) to assist tree-based models in identifying high-level patterns.

\subsubsection{Road Complexity Index}
We hypothesized that complex road environments increase accident probability but might decrease severity due to lower speeds. We engineered a \texttt{road\us complexity\us index}, a composite score normalized between 0 and 10. This index aggregates weighted scores from:
\begin{itemize}
    \item \textbf{Intersection Type:} High weights for roundabouts and multi-branch intersections.
    \item \textbf{Road Category:} Higher weights for urban communal ways vs. motorways.
    \item \textbf{Traffic Regime:} Penalties for variable assignment lanes.
    \item \textbf{Lane Count:} Higher complexity for multi-lane roads.
\end{itemize}
Complementing this, a binary \texttt{surface\us quality\us indicator} was created, set to 1 only if both the pavement condition was normal and the longitudinal profile was flat.

\subsubsection{Vehicle and User Attributes}
Vehicle categories were simplified from over 30 specific codes into 6 broad classes (Bicycle, Powered 2-3 Wheeler, Light Motor Vehicle, HGV/Truck, Bus/Coach, Other) to reduce dimensionality.
For users, we transformed the \texttt{year\us of\us birth} into an \texttt{age} feature and further binned it into sociologically relevant \texttt{age\us groups} (e.g., Child/Teen, Senior). Safety equipment flags (seatbelts, helmets, airbags) were consolidated from three separate columns into binary "Used/Not Used" indicators to resolve data sparsity.

\subsection{Feature Selection \& Cleaning}
Following engineering, the dataset underwent a rigorous cleaning process. Invalid data, such as speed limits exceeding 130 km/h or negative values for age, were filtered out. We removed high-cardinality identifiers (IDs, address strings) and columns with excessive missingness (e.g., \texttt{width\us central\us reservation}) that offered little predictive value.
Crucially, the raw target variable \texttt{injury\us severity} (4 classes) was re-mapped to an ordinal \texttt{injury\us target} (0: Uninjured, 1: Light Injury, 2: Hospitalized/Dead) to address class imbalance and better reflect the triage needs of first responders. The final dataset consists of 57 refined features ready for the modeling pipeline.

\subsection{Resampling}
Regarding the target value of injury severity, the dataset exhibits a clear class imbalance towards less severe cases (47\% non-injured, 36\% injured, and 16\% heavily injured) biasing models trained towards the majority class. Given the importance of correctly assessing cases of heavy injury, resampling was applied to the dataset to remove class imbalance.
Both over- (SMOTE) and undersampling were considered and tested. Given the large amount of data at disposal (over 400k) and considering compute constraints, random undersampling (130k) was ultimately chosen.

\section{Data Mining}
\label{sec:dm}
% \subsection{Setup for Model Selection and Evaluation}
First, we partitioned the dataset into training and testing subsets, using observations from 2019 to 2022 as the training data and the year 2023 as the test set. During model selection and hyperparameter tuning, only the training data was used, while the test set was kept strictly separate to prevent any data leakage and ensure an unbiased assessment of selected models during the final evaluation. 

Our primary metric for both model selection and evaluation was the macro F1-score. Since the task is an ordinal classification problem, metrics such as weighted Cohen’s kappa can also provide useful insights and were considered during evaluation. However, in our use case, correctly identifying the severely injured class is particularly critical: the consequences of failing to detect a severely injured person are far more serious than those of incorrectly classifying someone as injured when they are not.

In such settings, it can be reasonable to implement a cost matrix. However, this approach is highly sensitive to the chosen cost ratios and can easily lead to an excessive emphasis on the minority class at the expense of precision. It also makes it more difficult to interpret our results.
We therefore relied on macro F1 as our main metric and placed particular emphasis on the recall of the severely injured class. Because this class is highly underrepresented, using macro F1 as the optimization objective automatically increases the sensitivity to misclassifications of this class without explicitly introducing a cost matrix.

Therefore, instead of using a simple majority-vote baseline, we implemented a domain-specific baseline that relies exclusively on the speed-limit feature to predict accident severity \[
\hat{y} =
\begin{cases}
\text{uninjured}, & \text{if } \text{speed\_limit} \le 50, \\[4pt]
\text{injured}, & \text{if } \text{speed\_limit} < 100, \\[4pt]
\text{severely injured}, & \text{otherwise}.
\end{cases}
\]

\subsection{Models}
To gain an initial understanding of the difficulty of the prediction task, we experimented with a broad range of machine learning models while applying only minimal hyperparameter tuning including models based on logistic regression (ordinal, lasso, ridge), ensembles (Random Forests, HistGradientBoosting, CatBoost) and simple neural networks.
%
Across these experiments, we observed that all machine learning models substantially outperformed the baseline method. While originally considered, methods explicitly designed to leverage the ordinal structure of the target variable did not achieve better performance compared to other approaches in terms of both F1 and misclassifications error types, eliminating them from consideration. Applying Occam's Razor, our focus was narrowed to three models for fine-tuning and selection: Ridge Classification, Balanced Random Forest and CatBoost. 
%
While the first is Logistic Regression with applied L2-regularization and the second a random forest with rebalancing during subsampling, CatBoost is a boosting algorithm similar to XGBoost chosen for its improved support for categorical data, fitting to our data composition. 

\subsection{Model Selection}

\begin{table}[tb]
  \centering
  \begin{tabularx}{\textwidth}{l l X c}
    \toprule
    \textbf{Model} & \textbf{Hyperparameter} & \textbf{Search Space} & \textbf{Optimal Value} \\
    \midrule
    \textbf{Ridge} & alpha & $\{0.05, 0.10, \dots, 10\}$ & 2.0 \\
    \midrule
    \textbf{BRF} & estimators & $[50,\,400] \cap \mathbb{Z}$ & 400 \\
    & max\_depth & $[3,\,20] \cap \mathbb{Z}$ & 18 \\
    & min\_samples\_leaf & $[1,\,20] \cap \mathbb{Z}$ & 1 \\
    & max\_features & \{\texttt{sqrt}, \texttt{log2}\} & \texttt{sqrt} \\
    & criterion & \{\texttt{gini}, \texttt{entropy}\} & \texttt{gini} \\
    & sampling strategy & \{\texttt{all}, \texttt{not minority}\} & \texttt{all} \\
    & replacement & \{\texttt{True}, \texttt{False}\} & \texttt{False} \\
    & ccp alpha & $[10^{-6},\, 0.1]$ & $10^{-6}$ \\
    \midrule
    \textbf{CatBoost} & iterations & $[1000,\,7000] \cap \mathbb{Z}$ & 5000 \\
    & learning rate & $[0.01,\,0.2]$ & 0.0194 \\
    & depth & $[4,\,10] \cap \mathbb{Z}$ & 10 \\
    & L2 leaf regularization & $[10^{-2},\,10]$ & 0.01 \\
    & border count & $[32,\,255] \cap \mathbb{Z}$ & 32 \\
    \bottomrule
  \end{tabularx}
  \caption{Search space and optimal hyperparameters for Ridge, BRF and CatBoost.}
  \label{tab:hyperparams}
\end{table}

Considering the size of our dataset and computational constraints, model selection in terms of hyperparameter tuning was conducted for each model using 3-fold cross validation with shuffling to avoid biases from the original ordering, utilizing Bayesian Optimization and F1-Macro for the ensembles. While Ridge Regression could only be tuned regarding its regularization strength $\alpha$, both ensemble methods offered more options regarding tree pruning relevant for avoiding overfitting. \autoref{tab:hyperparams} shows the hyperparameters considered.
%
Approaches selection was similarly achieved using both F1-Macro and confusion matrices, used to evaluate recall/misclassifications on (high) injury cases, with the same 3-fold cross validation.


% \begin{figure}[h]
% \centering
% \begin{tikzpicture}
% \begin{axis}[
%     axis equal image,
%     enlargelimits=false,
%     xlabel={Predicted label},
%     ylabel={True label},
%     xtick={0.5,1.5},
%     xticklabels={Class 0, Class 1},
%     ytick={0.5,1.5},
%     yticklabels={Class 0, Class 1},
%     y dir=reverse,
%     colorbar,
% ]

% \addplot[
%     matrix plot*,
%     mesh/cols=2,         % number of columns (here: 2 classes)
%     point meta=explicit, % use the third column as color
% ]
% table[meta=z]{
% x y z
% 0 0 50
% 1 0 2
% 0 1 10
% 1 1 100
% };

% \end{axis}
% \end{tikzpicture}
% \caption{Heatmap confusion matrix}
% \end{figure}



\begin{itemize}
\item \textbf{Ridge Classifier:} Ridge classification provides fast and computationally efficient training and involves only a single hyperparameter to tune. Because ridge regularization tends to perform well when many features contribute small effects, it aligns well with our assumption that the predictive signal in our dataset arises from a broad set of variables rather than a few dominant predictors. In our experiments, we found it necessary to use under-sampling to compensate for the under-representation of the minority classes, as linear models are highly sensitive to class imbalance.

\item \textbf{Balanced Random Forest:} Although an individual decision tree performed reasonably, our experiments showed that using an ensemble of trees  significantly improved predictive performance while still retaining interpretability through feature importance scores and the option to inspect individual trees. We also found that the Balanced Random Forest variant is  especially useful: while macro F1 remained stable compared to the standard Random Forrest, performance on the severely injured class improved substantially, which is crucial for our application, even though slight reductions were observed for the non-injured and slightly-injured classes.

\item \textbf{CatBoost:} CatBoost achieved the strongest performance in our preliminary experiments, making it a natural candidate for more in-depth analysis. An important advantage of this method is its ability to efficiently handle categorical features, which constitute the majority of our dataset. We set the auto\_class\_weights parameter to Balanced, so that class weights are inversely proportional to class frequencies, removing the need for additional undersampling.

\end{itemize}

\subsection{Clustering}

In this study, we explore four clustering algorithms to analyze accident data: K-Means, K-Prototypes, HDBSCAN, and Agglomerative Hierarchical Clustering. Each method has distinct characteristics that motivate its selection.

\begin{itemize}
%\item \textbf{K-Means:}
%K-Means is a widely used centroid-based clustering algorithm that partitions data into a predefined number of clusters by minimizing the within-cluster sum of squares. It is computationally efficient and works well for datasets with predominantly numeric features. In this study, K-Means is applied to a one-hot encoded and scaled version of the accident data to provide a baseline clustering approach for comparison with algorithms designed for mixed data.

\item \textbf{K-Prototypes:}
K-Prototypes is well-suited for datasets that combine numerical and categorical variables, which makes it an appropriate choice for accident data dominated by categorical attributes. Its ability to cluster mixed‐type data in a single unified framework ensures that important categorical patterns, such as road characteristics or vehicle types, are not lost while still incorporating relevant numerical information.

\item \textbf{HDBSCAN:}
HDBSCAN is motivated by its strength in detecting clusters of varying density and its capacity to identify noise points. Accident datasets often contain heterogeneous patterns and rare accident types; therefore, a density-based method that can naturally isolate such irregular cases without forcing them into clusters is highly desirable. Using Gower distance allows HDBSCAN to operate effectively on mixed data.

\item \textbf{Hierarchical Clustering:}
Agglomerative hierarchical clustering is chosen for its interpretability and flexibility. It does not require pre-specifying the number of clusters. When paired with Gower distance, it becomes a useful exploratory tool for mixed-type accident variables, helping to reveal meaningful groupings even before a final cluster solution is selected.
\end{itemize}

Parameter tuning was conducted by varying the most influential hyperparameters of each clustering algorithm. 
For Agglomerative Clustering and K-Prototypes, the number of clusters was set to 
$k = 3, 5, 7$ to explore solutions of varying granularity. For HDBSCAN, which does not require a predefined number of clusters, the \textit{minimum cluster size} parameter was set to $k = 10, 20, 50$ to control the sensitivity of the algorithm to dense regions in the data.
These values were chosen as they provide interpretable cluster structures while remaining computationally feasible for the dataset size. 
 \\
After completing the parameter tuning and selecting the final clustering configuration based on interpretability and silhouette performance, a K-Prototypes model with $k=3$ produced a cluster label for each accident record. The resulting cluster assignments were incorporated into the dataset as an additional feature. \\
To derive meaningful accident profiles from the clustered dataset, we conducted a structured categorical overrepresentation analysis. For each cluster and each categorical feature, we computed the conditional distribution
\[
P(X = x \mid C = c),
\]
and compared it to the global distribution \(P(X=x)\).  
A category was considered \emph{cluster-characteristic} if it satisfied the following criteria:

\begin{itemize}
    \item \textbf{Lift filter:}  
    A minimum overrepresentation of  
    \[
      \text{lift}(x,c) = \frac{P(X=x \mid C=c)}{P(X=x)} > 1.5.
    \]
    This ensures the category is substantially more common in the cluster than in the overall population.

    \item \textbf{Support filter:}  
    The category must represent more than 3\% of observations within the cluster, preventing spurious rare categories from being selected.

    \item \textbf{Dominance and variance filters:}  
    Features were excluded if their distributions were nearly identical across clusters or if the same dominant category appeared in all clusters, as such features do not contribute to inter-cluster differentiation.
\end{itemize}
For numerical features, we computed summary statistics within each cluster, including the mean, median, standard deviation, and interquartile range, and compared these to the global distribution of the feature. A numerical feature was considered \emph{cluster-characteristic} if its mean or median significantly deviated from the global average, for instance, by more than one standard deviation, indicating that the cluster exhibits unusually high or low values for that feature.



\section{Evaluation}
% \subsection{Hyper Parameter Tuning}
% For the Ridge classifier, we only needed to tune the alpha parameter, which controls the regularization strength. We searched over values from 0.05 to 10.0 in increments of 0.05. For each alpha, we performed stratified 5-fold cross-validation on the training set and optimized with respect to the macro F1-score. The cross-validation splits were shuffled to avoid potential biases arising from the original ordering of the data. This procedure yielded an optimal alpha of 2.0.

% For the Balanced Random Forest classifier, the computational cost is considerably higher and the number of hyperparameters is substantially larger. To address this, we employ Bayesian Optimization, which explores the hyperparameter space in a more intelligent and efficient manner than grid or random search. We set the number of Bayesian optimization iterations to 30. Because we have a sufficiently large training set, we reduce the number of splits to a stratified 3-fold cross-validation and optimize for macro-F1. The full list of tuned hyperparameters is provided in Table~\ref{tab:brf_hyperparams}.

% For CatBoost, we applied the same Bayesian optimization scheme, tuning for macro-F1 using stratified 3-fold cross-validation on the training set. The resulting hyperparameter configuration is reported in Table~\ref{tab:catboost_hyperparams}. 

\subsection{Classification}

To evaluate the selected models, we followed the systematic methodology described in Section~\ref{sec:dm} and used the held-out test set from the year 2023, while the data from 2019-2022 were used for model training with the hyperparameter configurations derived above. Owing to the large size of the test set, its class distribution closely matches that of the full dataset (47\% non-injured, 36\% injured, and 16\% heavily injured), ensuring that our evaluation is effectively stratified with respect to injury severity. We report class-wise precision, recall, and F1-scores, along with micro-F1, weighted-F1, and weighted Cohen's kappa. We also compute confusion matrices and generate precision-recall curves.







\subsection{Clustering}
To ensure a consistent comparison between the algorithms, all clustering results were evaluated using the silhouette score, which measures the cohesion within clusters and the separation between them. 
The silhouette score was computed on the preprocessed feature space used by each algorithm, ensuring methodological consistency across heterogeneous clustering approaches. 
A higher silhouette score indicates a better-defined cluster structure. 
The table below summarizes the scores attained by each method:

\begin{table}[h!]
\centering
\begin{tabular}{l c c c}
\hline
\textbf{Algorithm} & \textbf{Parameter} & \textbf{Silhouette Score} & \textbf{Largest Cluster [\%]} \\
\hline
K-Prototypes   & 3  & 0.032305 & 38.8 \\
K-Prototypes   & 5  & 0.040767 & 38.8 \\
K-Prototypes   & 7  & 0.026212 & 38.8 \\
Agglomerative  & 3  & 0.107160 & 100.0 \\
Agglomerative  & 5  & 0.072454 & 100.0 \\
Agglomerative  & 7  & 0.062951 & 100.0 \\
HDBSCAN        & 10 & 0.088780 & 85.4 \\
HDBSCAN        & 25 & 0.070354 & 85.4 \\
HDBSCAN        & 50 & 0.048149 & 85.4 \\
\hline
\end{tabular}
\caption{Silhouette scores and largest cluster percentage for each algorithm and parameter setting.}
\label{tab:cluster_results}
\end{table}
Although Agglomerative Clustering and HDBSCAN yielded the highest silhouette scores, both methods produced highly unbalanced cluster solutions in which the vast majority of observations collapsed into a single cluster. Such degenerate solutions offer little analytical value, as they do not meaningfully differentiate between accident types.
In contrast, K-Prototypes generated more balanced clusters with substantially clearer interpretability. Among the tested configurations, choosing $k=5$ provided the best tradeoff between granularity and practical interpretability, making it the most suitable choice for deriving accident profiles.

\section{Results}

Our primary goal is to create a model capable of classifying injury severity to a satisfactory degree. We expect the clustering analysis to uncover specific, evidence-based "accident personas," such as low-speed urban collisions, high-velocity rural incidents, and collisions involving vulnerable road users. From the feature importance analysis, we expect to confirm that vehicle type (motorcycle vs. car) is a dominant predictor of severe injury. We also anticipate that factors like road category, lighting conditions, driver's age, and the use of safety equipment will be highly significant in predicting an individual's outcome.

\subsection{Clustering}
The following section presents detailed accident profiles for each cluster, summarizing the key categorical patterns and numerical deviations that distinguish them.
\subsubsection*{Cluster 0: Midday pedestrian-involved accidents with older road users}
This cluster is characterized by accidents that predominantly occur around midday and often involve older or middle-aged individuals. Pedestrian involvement is more typical here than in other clusters, and the accidents tend to take place in locations frequently associated with moderate traffic density.

\subsubsection*{Cluster 1: Night-time accidents with younger to middle-aged adults}
Accidents in this cluster occur mainly during nighttime and involve a broad spectrum of younger age groups, including young adults, adults, and teenagers. Pedestrian-related features indicate reduced visibility or unclear pedestrian actions, suggesting conditions with lower lighting and potentially higher uncertainty in movement patterns.

\subsubsection*{Cluster 2: Morning rush hour collisions}
This cluster mostly contains accidents happening during the morning peak traffic period. Specific collision types occur more frequently here, and certain weekdays are slightly overrepresented, pointing to commuting patterns. These accidents reflect typical rush-hour dynamics with increased traffic flow.

\subsubsection*{Cluster 3: High-speed urban location collisions with defined pedestrian involvement}
Cluster 3 shows a strong concentration of accidents in urban or densely built environments. Multiple collision types occur more frequently here, often involving pedestrian locations and actions typical for structured intersections or built-up areas. The cluster also exhibits a pattern of consistent seat-belt usage among vehicle occupants, suggesting regulated or lower-speed contexts.

\subsubsection*{Cluster 4: Low-speed high-frequency urban collisions with specific collision types}
This cluster is dominated by accidents in certain high-frequency urban locations and is marked by a few characteristic collision types. Pedestrian involvement can occur but is less central than in other clusters. The demographic structure is skewed toward adults, and the accident patterns suggest regular urban traffic situations with typical maneuver-related collisions.

\newpage
\section*{Ehrenwörtliche Erklärung}
Ich versichere, dass ich die beiliegende Bachelor-, Master-, Seminar-, oder
Projektarbeit ohne Hilfe Dritter und ohne Benutzung anderer als der angegebenen
Quellen und in der untenstehenden Tabelle angegebenen Hilfsmittel angefertigt
und die den benutzten Quellen wörtlich oder inhaltlich entnommenen Stellen als
solche kenntlich gemacht habe. Diese Arbeit hat in gleicher oder ähnlicher Form
noch keiner Prüfungsbehörde vorgelegen. Ich bin mir bewusst, dass eine falsche
Erklärung rechtliche Folgen haben wird.

% Declare below which AI tools you used in the process of writing your work,
% including text, image, code, and data generation. If you used a tool for a
% purpose not included in the list yet, add it to the list.
\begin{center}
  \textbf{Declaration of Used AI Tools} \\[.3em]
  \begin{tabularx}{\textwidth}{lXlc}
    \toprule
    Tool & Purpose & Where? & Useful? \\
    \midrule
    Gemini 2.5/3 Pro & Rephrasing & Throughout & +++ \\
    Gemini 2.5/3 Pro & Code Generation and Code Debugging & Throughout & +++ \\
    \bottomrule
  \end{tabularx}
\end{center}

\vspace{2cm}
\noindent Unterschrift\\
\noindent Mannheim, den 30.~Oktober 2025 \hfill
\end{document}

\end{document}
